{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "creative-harrison",
   "metadata": {},
   "source": [
    "# Hand In 3 - Frequent patterns\n",
    "\n",
    "Welcome to the handin on frequent patterns. \n",
    "This handin corresponds to the topics in Week 16--19 in the course.\n",
    "\n",
    "The handin IS \n",
    "* done in groups of two people\n",
    "* worth 10% of the grade\n",
    "\n",
    "For the handin, you will prepare a report in PDF format, by exporting the Jupyter notebook. \n",
    "Please submit\n",
    "1. The jupyter notebook file with your answers\n",
    "2. The PDF obtained by exporting the jupyter notebook\n",
    "\n",
    "Submit both files on Blackboard no later than **May 22nd kl. 23.59**.\n",
    "\n",
    "**The grading system**: Tasks are assigned a number of points based on the difficulty and time to solve it. The sum of\n",
    "the number of points is **80**. For the maximum grade you need to get at least _65 points_. The minimum grade (02 in the Danish scale)\n",
    "requires **at least** 24 points, with at least 8 points on of the first three Parts (Part 1,2,3).\n",
    "Good luck!\n",
    "\n",
    "**The exercise types**: There are three different types of exercises\n",
    "1. <span style='color: green'>**\\[Compute by hand\\]**</span> means that you should provide NO code, but show the main steps to reach the result (not all). \n",
    "2. <span style='color: green'>**\\[Motivate\\]**</span> means to provide a short answer of 1-2 lines indicating the main reasoning, e.g., the PageRank of a complete graph is 1/n in all nodes as all nodes are symmetric and are connected one another.\n",
    "3. <span style='color: green'>**\\[Describe\\]**</span> means to provide a potentially longer answer of 1-5 lines indicating the analysis of the data and the results. \n",
    "4. <span style='color: green'>**\\[Prove\\]**</span> means to provide a formal argument and NO code. \n",
    "5. <span style='color: green'>**\\[Implement\\]**</span> means to provide an implementation. Unless otherwise specified, you are allowed to use helper functions (e.g., ```np.mean```, ```itertools.combinations```, and so on). However, if the task is to implement an algorithm, by no means a call to a library that implements the same algorithm will be deemed as sufficient! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "resistant-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../utilities')\n",
    "\n",
    "\n",
    "import utilities\n",
    "\n",
    "# from load_data import load_dblp_citations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "designed-cornell",
   "metadata": {},
   "source": [
    "# Part 1: Subgraph mining (25 Points)\n",
    "In this part, we will work with subgraph mining algorithms. We will first solve some theory exercises and then implement two simple algorithms. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beneficial-softball",
   "metadata": {},
   "source": [
    "## Task 1.1 DFS codes (13 Points)\n",
    "\n",
    "### Task 1.1.1 (6 Points)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> Find the canonical (i.e., minimal) DFS code for the graph below. Try to eliminate some codes without generating the complete search tree. *Hint*: you can eliminate a code if you can show that it will have a larger code than some other code (e.g., using label ordering, degree). \n",
    "\n",
    "<div>\n",
    "<img src=\"images/dfs-codes.png\" width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "referenced-surprise",
   "metadata": {},
   "source": [
    "*******************\n",
    "1: A A A A B B C C D yes\n",
    "\n",
    "\n",
    "2: A A A A B B D C C\n",
    "\n",
    "\n",
    "\n",
    "(0,1,A,a,A)<br>\n",
    "(1,2,A,a,A)<br>\n",
    "(2,3,A,a,A)<br>\n",
    "(3,4,A,a,B)<br>\n",
    "(4,5,B,a,B)<br>\n",
    "(5,1,B,a,A) backwards edge<br> \n",
    "(5,2,B,a,A) backwards edge<br>\n",
    "(3,6,A,a,C)<br>\n",
    "(6,7,C,a,C)<br>\n",
    "(7,2,C,a,A) backwards edge<br>\n",
    "(6,8,C,a,D)<br>\n",
    "(8,1,D,a,A) backwards edge<br>\n",
    "(8,2,D,a,A) backwards edge<br>\n",
    "(8,3,D,a,A) backwards edge<br>\n",
    "\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "confused-budget",
   "metadata": {},
   "source": [
    "### Task 1.1.2 (4 Points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span> an extension to the DFS-code notation and the rules for the lexicographic ordering that handles the case of *directed* graphs. If that is not possible, state why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-rapid",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adjacent-correction",
   "metadata": {},
   "source": [
    "### Task 1.1.3 (3 Points)\n",
    " <span style='color: green'>**\\[Describe\\]**</span> (no need for pseudocode) a suitable way to find the _maximum_ DFS-code from the rules for _minimum_ DFS-codes that you already know from the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-exhibit",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sexual-creation",
   "metadata": {},
   "source": [
    "## Task 1.2 Maximum Independent Set (12 Points)\n",
    "\n",
    "### Task 1.2.1 (6 Points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span>  Sketch a proof that the Maximum Independent Set (MIS) support is anti-monotone, i.e., the support of a pattern $P'$ is no larger than _any_ pattern $P$ included in $P'$ (that is, $P$ is a sub-pattern of $P'$). To guide you into the proof, start from a set of matchings of the pattern $P'$ which corresponds to an independent set of nodes $I'$ in the overlap graph $G'_{O}$, same for the set of nodes $I$ in the overlap graph $G_O$ of $P$. Observe (_Observation 1_) that the **all** the matchings $f'$ of $P'$ contain matchings $f$ of $P$. Also observe (_Observation 2_) that if you take two matchings $f_1'$ and $f_2'$ of $P'$ and the corresponding matchings $f_1$ and $f_2$ of $P$ overlap, so do the matchings $f_1'$ and $f_2'$. Given these two observation what can you deduce on the independent sets $I'$ of $G'_O$ and $I$ of $G_O$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-graduation",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "functioning-reynolds",
   "metadata": {},
   "source": [
    "### Task 1.2.2 (6 Points)\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> In this exercise, we will program a simplified version of the Maximum Indepent Set (MIS) support. Your exercise is to construct an algorithm that takes in input a pattern $P$ and the matches of the pattern in the graph $G$ and finds the Maximum Independent Set (MIS) support. Since finding the MIS is NP-hard your exercise is to implement a simple greedy approximation  algorithm. To test the code you can use the graph and code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-being",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mis_support(P, matches): \n",
    "    \"\"\"\n",
    "    Returns the MIS support of a pattern. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    P:       The pattern represented as a networkx undirected graph object\n",
    "    matches: A list of subgraph isomorphic matches. Each match is a dictionary id_node_pattern -> id_node_graph\n",
    "    \"\"\"\n",
    "    mis = 0\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return mis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms import isomorphism\n",
    "\n",
    "# Example pattern\n",
    "P = nx.Graph()\n",
    "P.add_nodes_from([(1,{\"label\":\"A\"}), (2,{\"label\":\"B\"}), (3,{\"label\":\"C\"})])\n",
    "P.add_edges_from([(1,2),(2,3)])\n",
    "labels = nx.get_node_attributes(P, 'label') \n",
    "plt.figure(1)\n",
    "nx.draw(P,labels=labels)\n",
    "\n",
    "# Example graph\n",
    "G = nx.read_gml(\"data/graph.gml\", label='id')\n",
    "labels = nx.get_node_attributes(G, 'label') \n",
    "pos = nx.spring_layout(G)\n",
    "plt.figure(2)\n",
    "nx.draw(G,pos, labels=labels)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Find the matches of P in G\n",
    "nm = isomorphism.GraphMatcher(G,P,node_match=isomorphism.categorical_node_match(\"label\", \"A\"))\n",
    "matches = []\n",
    "for subgraph in nm.subgraph_monomorphisms_iter():\n",
    "    matches.append(subgraph)\n",
    "    print(subgraph)\n",
    "    \n",
    "print(\"The MIS support for pattern %s in G is: %f\" %(P.nodes, mis_support(P, matches)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXTRA CODE BLOCK HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-evolution",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "front-contact",
   "metadata": {},
   "source": [
    "# Part 2: Frequent itemsets (25 Points)\n",
    "We have learned the Apriori and FP-Growth algorithms for mining frequent itemsets. In this part, we will implement these algorithms and test them against each other. \n",
    "\n",
    "We will use the anonymized real-world `retail market basket` data from: http://fimi.ua.ac.be/data/.\n",
    "This data comes from an anonymous Belgian retail store, and was donated by Tom Brijs from Limburgs Universitair Centrum, Belgium. The original data contains 16,470 different items and 88,162 transactions. You may only work with the top-50 items in terms of occurrence frequency.\n",
    "_Hint:_ We have used this dataset before.\n",
    "\n",
    "The variable **retail_small** contains the top-50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "extensive-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.load_data import load_market_basket\n",
    "\n",
    "\n",
    "def filter_transactions(T, k=50):\n",
    "    \"\"\"\n",
    "        Keep only the top k items in the transactions.\n",
    "        Remove transactions that become empty.\n",
    "    \"\"\"\n",
    "    # Count occurences of each item\n",
    "    counts = [0] * 16470\n",
    "    for t in T:\n",
    "        for i in t:\n",
    "            counts[i] += 1\n",
    "\n",
    "    # Sort and select top k\n",
    "    counts = np.array(counts)\n",
    "    order  = np.argsort(counts)[::-1] # reverse the sorted order\n",
    "\n",
    "    indexes_to_keep = order[:k]       # Keep the top k items\n",
    "    index_set = set(indexes_to_keep)  # Convert to python set for efficiency\n",
    "\n",
    "    # Filter transactions\n",
    "    T_new = [t_ for t_ in  [list(filter(lambda i: i in index_set, t)) for t in T]  if t_]\n",
    "    return T_new\n",
    "\n",
    "retail = load_market_basket()\n",
    "retail_small = filter_transactions(retail)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "incorrect-psychology",
   "metadata": {},
   "source": [
    "## Task 2.1 Association Rules (4 Points)\n",
    "Consider the following table\n",
    "\n",
    "| transaction ID \t| Items           \t|\n",
    "|----------------\t|-----------------\t|\n",
    "| 1              \t| Ape,Cat,Dog,Cow     \t|\n",
    "| 2              \t| Cat,Dog,Pig,Cow \t|\n",
    "| 3              \t| Dog,Bat,Pig,Cow \t|\n",
    "| 4              \t| Dog,Pig,Cow     \t|\n",
    "| 5              \t| Dog,Cow         \t|\n",
    "| 6              \t| Cat,Cow         \t|\n",
    "| 7              \t| Ape,Bat,Fox     \t|\n",
    "| 8              \t| Ape,Cow         \t|\n",
    "| 9              \t| Ape,Dog,Cow     \t|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "acute-shade",
   "metadata": {},
   "source": [
    "### Task 2.1.1 (0.5 Points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span> What is the count of the itemset {Dog,Pig,Cow} ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-account",
   "metadata": {},
   "source": [
    "*******************\n",
    "The count of {Dog,Pig,Cow} is 3 \\\n",
    "The transaction id's which contribute towards the count are: 2, 3, 4\n",
    "\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "strategic-adolescent",
   "metadata": {},
   "source": [
    "### Task 2.1.2 (0.5 Points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span>What is the support and confidence of the association rule {Dog,Pig}->Cow ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "modular-kennedy",
   "metadata": {},
   "source": [
    "*******************\n",
    "The support is:\n",
    "$$\n",
    "s = \\frac{\\sigma(Dog, Pig, Cow)}{|T|} = \\frac{3}{9} \\approx 0.333\n",
    "$$\n",
    "The confidence is:\n",
    "$$\n",
    "c = \\frac{\\sigma(Dog, Pig, Cow)}{\\sigma(Dog, Pig)} = \\frac{3}{3} = 1\n",
    "$$\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "neither-seattle",
   "metadata": {},
   "source": [
    "### Task 2.1.3 (1.5 Point)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> Consider the application of the Apriori algorithm to find all the frequent itemsets\n",
    "whose counts are at least 3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "optimum-prime",
   "metadata": {},
   "source": [
    "*******************\n",
    "When we start the algorithm, $k =1, C_1 = \\text{all items}$.\n",
    "Now let's determine $L_1$:\n",
    "$$ L_1 = \\{ \\{Ape\\}, \\{Cat\\}, \\{Dog\\}, \\{Cow\\}, \\{Pig\\} \\} $$\n",
    "$\\{Fox\\}$ and $\\{Bat\\}$ are removed, as the count of these itemsets in the database is below 3.\n",
    "\n",
    "\n",
    "We now compute the new candidate set $C_2$:\n",
    "$$ \n",
    "\\begin{align*}\n",
    "C_2 &= \\{ \\\\\n",
    "        &&&\\{Ape, Cat\\}, \\{Ape, Dog\\}, \\{Ape, Cow\\}, \\{Ape, Pig\\}, \\\\\n",
    "        &&&\\{Cat, Dog\\}, \\{Cat, Cow\\}, \\{Cat, Pig\\},  \\\\\n",
    "        &&&\\{Dog, Cow\\}, \\{Dog, Pig\\} \\\\\n",
    "        &&&\\{Cow, Pig\\} \\\\\n",
    "    &\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "And compute $L_2$ by pruning infrequent itemsets:\n",
    "$$ \n",
    "L_2 = \\{ \\{Ape, Cow\\}, \\{Cat, Cow\\}, \\{Dog, Cow\\}, \\{Dog, Pig\\}, \\{Cow, Pig\\} \\}\n",
    "$$\n",
    "We can now compute a new candidate set $C_3$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "C_3 &= \\{ \\\\\n",
    "        &&&\\{Cow, Ape, Cat\\}, \\{Cow, Ape, Dog\\}, \\{Cow, Ape, Pig\\}, \\\\\n",
    "        &&&\\{Cow, Cat, Dog\\}, \\{Cow, Cat, Pig\\}, \\{Cow, Dog, Pig\\}  \\\\\n",
    "    &\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "Once we prune $C_3$, we have $L_3$:\n",
    "$$ \n",
    "L_3 = \\{ \\{Cow, Dog, Pig\\} \\}\n",
    "$$\n",
    "And now the algorithm terminates.\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "humanitarian-walnut",
   "metadata": {},
   "source": [
    "### Task 2.1.4 (1.5 Point)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> Find all the association rules with support at least 1/3 and confidence at least 1/2.\n",
    "\n",
    "| transaction ID \t| Items           \t|\n",
    "|----------------\t|-----------------\t|\n",
    "| 1              \t| Ape,Cat,Dog,Cow     \t|\n",
    "| 2              \t| Cat,Dog,Pig,Cow \t|\n",
    "| 3              \t| Dog,Bat,Pig,Cow \t|\n",
    "| 4              \t| Dog,Pig,Cow     \t|\n",
    "| 5              \t| Dog,Cow         \t|\n",
    "| 6              \t| Cat,Cow         \t|\n",
    "| 7              \t| Ape,Bat,Fox     \t|\n",
    "| 8              \t| Ape,Cow         \t|\n",
    "| 9              \t| Ape,Dog,Cow     \t|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adverse-wright",
   "metadata": {},
   "source": [
    "*******************\n",
    "Let's start by first computing all association rules with support of at least 1/3.\\\n",
    "Since support is computed by $s = \\frac{\\sigma(I)}{\\vert T\\vert}$ where $I$ is an itemset, and $T$ is the set of transactions, we can immediately see, that we have to find itemsets $I$, such that:\n",
    "$$ s \\geq \\frac{1}{3} = \\frac{\\sigma(I)}{\\vert T\\vert} = \\frac{\\sigma(I)}{9} = \\frac{\\sigma(I)/3}{3} $$\n",
    "thus we see the constraint on $\\sigma(I)$:\n",
    "$$ \\frac{1}{3} = \\frac{\\sigma(I)/3}{3} \\implies \\sigma(I) = 3$$\n",
    "This shows, that in the case that $\\sigma(I)$ is less than 3, then $I$ will not satisfy our support requirement of being at least 1/3.\\\n",
    "So now we have reduced the problem to finding itemsets $I$ such that:\n",
    "$$ \\sigma(I) \\geq 3 $$\n",
    "We know from the previous exercise, that\n",
    "$$\n",
    "\\begin{align*}\n",
    "L_1 &= \\{ \\{Ape\\}, \\{Cat\\}, \\{Dog\\}, \\{Cow\\}, \\{Pig\\} \\} \\\\\n",
    "L_2 &= \\{ \\{Ape, Cow\\}, \\{Cat, Cow\\}, \\{Dog, Cow\\}, \\{Dog, Pig\\}, \\{Cow, Pig\\} \\} \\\\\n",
    "L_3 &= \\{ \\{Cow, Dog, Pig\\} \\}\n",
    "\\end{align*}\n",
    "$$\n",
    "So since these itemsets have a $\\texttt{minsup}$ of 3, we can use these itemsets to search for association rules with confidence at least a half. We will ignore all rules such as $S \\to \\emptyset$ and $\\emptyset \\to S$, as these are not very interesting - thus all itemsets in $L_1$ for instance are not considered. This leaves us with the following rules to consider for $L_2$ and $L_3$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "L_2:\\\\\n",
    "\\{Ape\\} &\\to \\{Cow\\}  &\\quad c = \\sigma(\\{Ape, Cow\\})/\\sigma(\\{Ape\\}) = 3/4 &> 1/2 \\\\\n",
    "\\{Cow\\} &\\to \\{Ape\\}  &\\quad c = \\sigma(\\{Ape, Cow\\})/\\sigma(\\{Cow\\}) = 3/8 &< 1/2 \\\\\n",
    "\\{Cat\\} &\\to \\{Cow\\}  &\\quad c = \\sigma(\\{Cat, Cow\\})/\\sigma(\\{Cat\\}) = 3/3 &> 1/2 \\\\\n",
    "\\{Cow\\} &\\to \\{Cat\\}  &\\quad c = \\sigma(\\{Cat, Cow\\})/\\sigma(\\{Cow\\}) = 3/8 &< 1/2 \\\\\n",
    "\\{Dog\\} &\\to \\{Cow\\}  &\\quad c = \\sigma(\\{Dog, Cow\\})/\\sigma(\\{Dog\\}) = 6/6 &> 1/2 \\\\\n",
    "\\{Cow\\} &\\to \\{Dog\\}  &\\quad c = \\sigma(\\{Dog, Cow\\})/\\sigma(\\{Cow\\}) = 6/8 &> 1/2 \\\\\n",
    "\\{Dog\\} &\\to \\{Pig\\}  &\\quad c = \\sigma(\\{Dog, Pig\\})/\\sigma(\\{Dog\\}) = 3/6 &= 1/2 \\\\\n",
    "\\{Pig\\} &\\to \\{Dog\\}  &\\quad c = \\sigma(\\{Dog, Pig\\})/\\sigma(\\{Pig\\}) = 3/3 &> 1/2 \\\\\n",
    "\\{Cow\\} &\\to \\{Pig\\}  &\\quad c = \\sigma(\\{Cow, Pig\\})/\\sigma(\\{Cow\\}) = 3/8 &< 1/2 \\\\\n",
    "\\{Pig\\} &\\to \\{Cow\\}  &\\quad c = \\sigma(\\{Cow, Pig\\})/\\sigma(\\{Pig\\}) = 3/3 &> 1/2 \\\\[2mm]\n",
    "L_3:\\\\\n",
    "\\{Cow, Dog\\} &\\to \\{Pig\\} &\\quad c = \\sigma(\\{Cow, Dog, Pig\\})/\\sigma(\\{Cow, Dog\\}) = 3/6 &= 1/2 \\\\\n",
    "\\{Cow, Pig\\} &\\to \\{Dog\\} &\\quad c = \\sigma(\\{Cow, Dog, Pig\\})/\\sigma(\\{Cow, Pig\\}) = 3/3 &> 1/2 \\\\\n",
    "\\{Dog, Pig\\} &\\to \\{Cow\\} &\\quad c = \\sigma(\\{Cow, Dog, Pig\\})/\\sigma(\\{Dog, Pig\\}) = 3/3 &> 1/2 \\\\\n",
    "\\{Cow\\} &\\to \\{Dog, Pig\\} &\\quad c = \\sigma(\\{Cow, Dog, Pig\\})/\\sigma(\\{Cow\\}) = 3/8 &< 1/2 \\\\\n",
    "\\{Pig\\} &\\to \\{Dog, Cow\\} &\\quad c = \\sigma(\\{Cow, Dog, Pig\\})/\\sigma(\\{Pig\\}) = 3/3 &> 1/2 \\\\\n",
    "\\{Dog\\} &\\to \\{Pig, Cow\\} &\\quad c = \\sigma(\\{Cow, Dog, Pig\\})/\\sigma(\\{Dog\\}) = 3/6 &= 1/2 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Thus, we are left with the following association rules, which has support of at least 1/3 and confidence at least 1/2:\n",
    "$$\n",
    "\\{Ape\\} \\to \\{Cow\\}, \\{Cat\\} \\to \\{Cow\\}, \\{Dog\\} \\to \\{Cow\\}, \\{Cow\\} \\to \\{Dog\\}, \\{Dog\\} \\to \\{Pig\\}, \\\\\n",
    "\\{Pig\\} \\to \\{Dog\\}, \\{Pig\\} \\to \\{Cow\\}, \\{Cow, Dog\\} \\to \\{Pig\\}, \\{Cow, Pig\\} \\to \\{Dog\\}, \\\\\n",
    "\\{Dog, Pig\\} \\to \\{Cow\\}, \\{Pig\\} \\to \\{Dog, Cow\\}, \\{Dog\\} \\to \\{Pig, Cow\\}\n",
    "$$\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "voluntary-transformation",
   "metadata": {},
   "source": [
    "## Task 2.2 A Priori algorithm (9 Points)\n",
    "\n",
    "### Task 2.2.1(7 Points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Develop an implementation of the Apriori algorithm. You can look at your implementation from the exercises (note that this one is slightly different to simplify comparison with FP-Growth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "productive-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pig: 3\n",
      "Cat: 3\n",
      "Cow: 8\n",
      "Ape: 4\n",
      "Dog: 6\n",
      "Cat, Cow: 3\n",
      "Dog, Cow: 6\n",
      "Cow, Pig: 3\n",
      "Ape, Cow: 3\n",
      "Dog, Pig: 3\n",
      "Dog, Cow, Pig: 3\n"
     ]
    }
   ],
   "source": [
    "def apriori_algorithm(T, min_support=10):\n",
    "    \"\"\"\n",
    "        Apriori algorithm for mining frequent itemsets and association rules. \n",
    "        This implementation should just find frequent itemsets, and ignore the rule generation.\n",
    "        Inputs:\n",
    "            T:               A list of lists, each inner list will contiain integer-item-ids. \n",
    "                             Example: T = [[1, 2, 5], [2, 3, 4], [1, 6]]\n",
    "            min_support:     int: The total number of occurences needed for an itemset to be considered frequent\n",
    "        \n",
    "        Outputs:\n",
    "            itemsets:        Dictionary of with keys as frequent itemset, and value as the total count of this itemset \n",
    "    \"\"\"\n",
    "    itemsets = dict()\n",
    "    ### TODO Your code here\n",
    "    \n",
    "    # Create a list of all unique items from T\n",
    "    C_k = set()\n",
    "    [[C_k.add((i,)) for i in t] for t in T]\n",
    "    # Now k = 1, and C_k contains all candidates of size 1\n",
    "\n",
    "    while len(C_k) > 0:\n",
    "        L_k = set()\n",
    "        # Frequent itemset generation\n",
    "        counts = dict.fromkeys(C_k, 0)\n",
    "        for c in C_k:\n",
    "            for t in T:\n",
    "                if set(c).issubset(t):\n",
    "                    counts[c] = counts[c]+1\n",
    "        # Pruning candidates not satisfying min_support\n",
    "        [L_k.add(c) for c in C_k if counts[c] >= min_support]\n",
    "        \n",
    "        # Add L_k to itemsets\n",
    "        for item_set in L_k:\n",
    "            itemsets[item_set] = counts[item_set]            \n",
    "\n",
    "        # Candidate generation\n",
    "        C_k = compute_candidates(L_k)\n",
    "\n",
    "    ### TODO Your code here\n",
    "    return itemsets\n",
    "\n",
    "def compute_candidates(prev_itemset):\n",
    "    Ck = set()\n",
    "    # Join step\n",
    "    for itemset in prev_itemset:\n",
    "        its1 = tuple(sorted(itemset))\n",
    "        for itemset2 in prev_itemset:\n",
    "            its2 = tuple(sorted(itemset2))\n",
    "            if its1[:-1] == its2[:-1]:\n",
    "                if its1[-1] < its2[-1]: Ck.add(its1 + its2[-1:])\n",
    "\n",
    "    # Pruning step\n",
    "    to_remove = set()\n",
    "    for c in Ck:\n",
    "        for subset in combinations(c, len(c)-1):\n",
    "            if not subset in prev_itemset:\n",
    "                to_remove.add(c)\n",
    "                break\n",
    "    for c in to_remove:\n",
    "        Ck.remove(c)\n",
    "    \n",
    "    return Ck\n",
    "\n",
    "#TODO: Remove tests below before handing in\n",
    "\n",
    "items = [\"Bread\", \"Milk\", \"Diaper\", \"Beer\", \"Eggs\", \"Coke\"]\n",
    "def i(s):\n",
    "    return items.index(s)+1\n",
    "T = [[i(\"Bread\"), i(\"Milk\")],\n",
    "     [i(\"Bread\"), i(\"Diaper\"), i(\"Beer\"), i(\"Eggs\")],\n",
    "     [i(\"Milk\"), i(\"Diaper\"), i(\"Beer\"), i(\"Coke\")],\n",
    "     [i(\"Bread\"), i(\"Milk\"), i(\"Diaper\"), i(\"Beer\")],\n",
    "     [i(\"Bread\"), i(\"Milk\"), i(\"Diaper\"), i(\"Coke\")]]\n",
    "\n",
    "def print_freq(d):\n",
    "    for x in d.keys():\n",
    "        print(*list(map(lambda k: items[k-1], list(x))), sep=\", \", end=\"\")\n",
    "        print(\":\", d[x])\n",
    "\n",
    "#| transaction ID \t| Items           \t|\n",
    "#|----------------\t|-----------------\t|\n",
    "#| 1              \t| Ape,Cat,Dog,Cow     \t|\n",
    "#| 2              \t| Cat,Dog,Pig,Cow \t|\n",
    "#| 3              \t| Dog,Bat,Pig,Cow \t|\n",
    "#| 4              \t| Dog,Pig,Cow     \t|\n",
    "#| 5              \t| Dog,Cow         \t|\n",
    "#| 6              \t| Cat,Cow         \t|\n",
    "#| 7              \t| Ape,Bat,Fox     \t|\n",
    "#| 8              \t| Ape,Cow         \t|\n",
    "#| 9              \t| Ape,Dog,Cow     \t|\n",
    "\n",
    "items = [\"Ape\", \"Cat\", \"Dog\", \"Cow\", \"Bat\", \"Pig\", \"Fox\"]\n",
    "def i(s):\n",
    "    return items.index(s)+1\n",
    "T = [[i(\"Ape\"), i(\"Cat\"), i(\"Dog\"), i(\"Cow\")],\n",
    "     [i(\"Cat\"), i(\"Dog\"), i(\"Pig\"), i(\"Cow\")],\n",
    "     [i(\"Dog\"), i(\"Bat\"), i(\"Pig\"), i(\"Cow\")],\n",
    "     [i(\"Dog\"), i(\"Pig\"), i(\"Cow\")],\n",
    "     [i(\"Dog\"), i(\"Cow\")],\n",
    "     [i(\"Cat\"), i(\"Cow\")],\n",
    "     [i(\"Ape\"), i(\"Bat\"), i(\"Fox\")],\n",
    "     [i(\"Ape\"), i(\"Cow\")],\n",
    "     [i(\"Ape\"), i(\"Dog\"), i(\"Cow\")]\n",
    "     ]\n",
    "\n",
    "print_freq(apriori_algorithm(T, 3))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "unauthorized-essence",
   "metadata": {},
   "source": [
    "### Task 2.2.2 (2 Points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Run Apriori on the data-set (using the **retail** variable and not the small one). Try a few different values of min_support. </br>\n",
    "<span style='color: green'>**\\[Describe\\]**</span>Roughly how large does min_support need to be before no itemsets of size 2 are found? (You don't need to find the excact value. Nearest 1000 is fine).\n",
    "\n",
    "Note that the dataset is reasonably large, so this **can take up a large amount of time depending on your value of min support and implementation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "timely-trash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(48,): 42135, (39,): 50675}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori_algorithm(retail, 29143)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "exact-department",
   "metadata": {},
   "source": [
    "******************\n",
    "$\\texttt{min\\_support}$ has to be at least 29143 in order to prune the last itemset of size 2; namely the itemset (39, 48) with a count of 29142.\\\n",
    "As the itemset (39, 48) is the only frequent itemset of size 2 with $\\texttt{min\\_support} = 29142$, this tells us that if 48 or 39 is in a transaction where both items are not present, then 48 (and/or) 39 will be frequent at $\\texttt{min\\_support} = 29143$. This is indeed the case, as the itemset 48 has a count of 42135 and the itemset 39 has a count of 50675, which is the only remaining size-1 itemsets.\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adaptive-copying",
   "metadata": {},
   "source": [
    "## Task 2.3 FP-Growth (9 Points)\n",
    "\n",
    "### Task 2.3.1 (7 Points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Complete the implementation of FP-Growth below. You only need to implement growing the tree and building the header table. It is clearly marked where you need to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fourth-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FP_Tree:\n",
    "    def __init__(self, T, min_support=10):\n",
    "        \"\"\"\n",
    "        Constructor for FP_Tree. Should correctly build an FP-Tree with header table.\n",
    "        Hint: I strongly advise you to implement the missing sections of the Node class before this one\n",
    "        \n",
    "        Inputs:\n",
    "            T:               A list of lists, each inner list will contiain integer-item-ids. \n",
    "                             Example: T = [[1, 2, 5], [2, 3, 4], [1, 6]]\n",
    "            min_support:     The total number of occurences needed to keep the itemset.\n",
    "        \"\"\"\n",
    "        self.min_support    = min_support\n",
    "        self.header_table   = {}\n",
    "        self.root           = Node(header_table = self.header_table)\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        for t in T:\n",
    "            self.root.add_path(t)\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### Common functions for FP-tree and Conditional FP-tree\n",
    "    ### You do not need to modify the rest of this class\n",
    "    def generate_pattern(self, keys, support):\n",
    "        return tuple(keys + self.get_suffix()), support\n",
    "    \n",
    "    def get_suffix(self):\n",
    "        return []\n",
    "    \n",
    "    # This is the main function for generating frequent itemsets. You do not need to modify this,\n",
    "    # but I recommend reading and trying to understand it.\n",
    "    def mine_frequent_itemsets(self, res=None):\n",
    "        if res is None: res = []\n",
    "        \n",
    "        if self.root.is_single_path():\n",
    "            keys = list(self.header_table.keys())\n",
    "            key_idx = {k:i for i, k in enumerate(keys)}\n",
    "            counts = [self.header_table[k].count for k in keys]\n",
    "            \n",
    "            for key_pair in itertools.chain(*[itertools.combinations(keys, k) for k in range(1, len(keys)+1)]):\n",
    "                support = min([counts[key_idx[k]] for k in key_pair])\n",
    "                if support >= self.min_support: \n",
    "                    res.append(self.generate_pattern(list(key_pair), support))\n",
    "         \n",
    "        else: # Not single path\n",
    "            for key, node in self.header_table.items():\n",
    "                support = node.support()\n",
    "                \n",
    "                if support >= self.min_support:\n",
    "                    res.append( self.generate_pattern([key], support) )\n",
    "                \n",
    "                basis = []\n",
    "                while node is not None:\n",
    "                    curr_node = node\n",
    "                    node = node.nodelink\n",
    "                    \n",
    "                    if curr_node.parent is None:  continue\n",
    "                        \n",
    "                    path = curr_node.path(limit=curr_node.count)[:-1]\n",
    "                    if len(path) == 0:  continue\n",
    "                        \n",
    "                    basis.append( path )\n",
    "                    \n",
    "                if len(basis) == 0: continue\n",
    "                    \n",
    "                conditional_tree = Conditional_FP_Tree(self.min_support, [key] + self.get_suffix(), basis)\n",
    "                if conditional_tree.root is None: continue\n",
    "                    \n",
    "                conditional_tree.mine_frequent_itemsets(res=res)\n",
    "        return res\n",
    "\n",
    "\n",
    "# You don't need to modify anything in this class\n",
    "class Conditional_FP_Tree(FP_Tree):\n",
    "    def __init__(self, min_support, suffix, basis): \n",
    "        self.min_support    = min_support\n",
    "        self.suffix         = suffix\n",
    "        self.header_table   = {} # This will hold all unique items\n",
    "        \n",
    "        self.root           = Node(header_table=self.header_table)\n",
    "        \n",
    "        self.build_tree(basis)\n",
    "        # self.root           = prune(self.root, min_support)\n",
    "        if self.root is None: print(\"WARNING: root is empty after pruning\")\n",
    "        \n",
    "    def build_tree(self, basis):\n",
    "        for b in basis:\n",
    "            count = b[0][1]\n",
    "            path = list(map(lambda x: x[0], b))\n",
    "            for i in range(count):\n",
    "                self.root.add_path(path)\n",
    "    \n",
    "    def get_suffix(self):\n",
    "        return self.suffix\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, header_table, value=None, parent=None, path=None):\n",
    "        \"\"\"\n",
    "        Constructor for Node class, which is used for the FP-Tree. \n",
    "        Inputs:\n",
    "            header_table:    Dict. Should be same dict for all nodes in the tree\n",
    "            value:           Integer id of the item the node represents\n",
    "            parent:          Parent Node. None if root node\n",
    "            path:            List of node values for a path that should start in this node.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.children     = {} # This is a dict from id -> node\n",
    "        self.header_table = header_table \n",
    "        self.nodelink     = None\n",
    "        self.value        = None\n",
    "        self.parent       = None\n",
    "        self.count        = 0\n",
    "        \n",
    "        if value is not None: # Only root node should have None as value\n",
    "            self.value          = value\n",
    "            self.parent         = parent\n",
    "            # YOUR CODE HERE\n",
    "            self.count = 1\n",
    "            # YOUR CODE HERE\n",
    "        \n",
    "        if path is not None: \n",
    "            self.add_path(path)\n",
    "            \n",
    "    \n",
    "    def add_path(self, path):\n",
    "        \"\"\"\n",
    "        Function for adding a path to tree. \n",
    "        Should follow an existing path and increment count while such a path exists. \n",
    "        If no path exists (or only partial path exists), this function should create or complete such a path\n",
    "        Hint: Recursion might be helpful.\n",
    "        Inputs:\n",
    "            path:            A list node values. \n",
    "                             Example: path = [1, 2, 5]\n",
    "        \"\"\"\n",
    "        ### YOUR CODE\n",
    "        # See if we can follow a path from this node\n",
    "        if path[0] in self.children:\n",
    "            child_to_follow = self.children[path[0]]\n",
    "            child_to_follow.count += 1 # Increment the count, as we pass this node\n",
    "            # Try to add the remaining path from the child to follow\n",
    "            if len(path) >= 2: # Why two? Well, we just inserted path[0]\n",
    "                child_to_follow.add_path(path[1:])\n",
    "        else:\n",
    "            # No path was found. We should insert the path to the node as a child\n",
    "            new_node = Node(header_table=self.header_table,value=path[0],parent=self,path=None)\n",
    "            self.children[path[0]] = new_node\n",
    "\n",
    "            if path[0] not in self.header_table:\n",
    "                self.header_table[path[0]] = new_node\n",
    "            else:\n",
    "                # Set nodelink of the newly inserted node to point at the old node\n",
    "                new_node.nodelink = self.header_table[path[0]]\n",
    "                # Update header table: Should point at the newly inserted node\n",
    "                self.header_table[path[0]] = new_node\n",
    "            \n",
    "            if len(path) >= 2:\n",
    "                new_node.add_path(path[1:])\n",
    "        \n",
    "        \n",
    "        ### YOUR CODE\n",
    "    \n",
    "    \n",
    "    # Functions for frequent items-sets and rule mining below. You do not need to modify these\n",
    "    def is_single_path(self):\n",
    "        if   len(self.children) == 0: return True \n",
    "        elif len(self.children) >  1: return False\n",
    "        else:  # len == 1\n",
    "            key = next((k for k in self.children.keys()))\n",
    "            return self.children[key].is_single_path()\n",
    "    \n",
    "    def support(self, verbose=False):\n",
    "        if verbose: print(\"Counting support, this value is \", self.value, \" with count \", self.count, \" and parent \", self.parent.value)\n",
    "            \n",
    "        if self.nodelink is not None: return self.count + self.nodelink.support(verbose)\n",
    "        else:                         return self.count\n",
    "    \n",
    "    def path(self, limit=-1):\n",
    "        if self.value is None: \n",
    "            return []\n",
    "        else:                  \n",
    "            count = self.count if limit == -1 else min(self.count, limit)\n",
    "            return self.parent.path(limit=limit) + [(self.value, count)]\n",
    "    \n",
    "    def print(self, indent=\"\", spacing=\"----|-\"):\n",
    "        print(indent + str(self.value) + \":\" + str(self.count))\n",
    "        for v in self.children.values():\n",
    "            v.print(indent=indent + spacing)\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "undefined-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing transactions:\n",
      "AB\n",
      "BCD\n",
      "ACDE\n",
      "ADE\n",
      "ABC\n",
      "ABCD\n",
      "BC\n",
      "ABC\n",
      "ABD\n",
      "BCE\n",
      "\n",
      "Printing FP Tree:\n",
      "None:0\n",
      "----|-1:7\n",
      "----|-----|-2:5\n",
      "----|-----|-----|-3:3\n",
      "----|-----|-----|-----|-4:1\n",
      "----|-----|-----|-4:1\n",
      "----|-----|-3:1\n",
      "----|-----|-----|-4:1\n",
      "----|-----|-----|-----|-5:1\n",
      "----|-----|-4:1\n",
      "----|-----|-----|-5:1\n",
      "----|-2:3\n",
      "----|-----|-3:3\n",
      "----|-----|-----|-4:1\n",
      "----|-----|-----|-5:1\n",
      "\n",
      "Header Table:\n",
      "1 : A-root\n",
      "2 : B-root\n",
      "3 : C-B-A-root\n",
      "4 : D-B-A-root\n",
      "5 : E-C-B-root\n"
     ]
    }
   ],
   "source": [
    "### YOUR TEST CODE HERE\n",
    "\n",
    "# Use l as symbols\n",
    "l = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "# Convert symbol to integer ID\n",
    "def i(s):\n",
    "    return l.index(s)+1\n",
    "\n",
    "# Transactions as ID's from symbols\n",
    "# (T is from example in slides)\n",
    "T = [\n",
    "    [i(\"A\"), i(\"B\")],\n",
    "    [i(\"B\"), i(\"C\"), i(\"D\")],\n",
    "    [i(\"A\"), i(\"C\"), i(\"D\"), i(\"E\")],\n",
    "    [i(\"A\"), i(\"D\"), i(\"E\")],\n",
    "    [i(\"A\"), i(\"B\"), i(\"C\")],\n",
    "    [i(\"A\"), i(\"B\"), i(\"C\"), i(\"D\")],\n",
    "    [i(\"B\"), i(\"C\")],\n",
    "    [i(\"A\"), i(\"B\"), i(\"C\")],\n",
    "    [i(\"A\"), i(\"B\"), i(\"D\")],\n",
    "    [i(\"B\"), i(\"C\"), i(\"E\")]\n",
    "]\n",
    "\n",
    "# Print symbols from integer IDs in transaction T\n",
    "def print_inv(T):\n",
    "    print(\"Printing transactions:\")\n",
    "    for t in T:\n",
    "        for i in t:\n",
    "            print(l[i-1], end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "print_inv(T)\n",
    "\n",
    "print(\"\\nPrinting FP Tree:\")\n",
    "fp_t = FP_Tree(T)\n",
    "fp_t.root.print()\n",
    "\n",
    "print(\"\\nHeader Table:\")\n",
    "def get_path(n):\n",
    "    if n.value is None:\n",
    "        return \"root\"\n",
    "    return l[n.value-1] + \"-\" + get_path(n.parent)\n",
    "for h in fp_t.root.header_table.keys():\n",
    "    print(h, \":\", get_path(fp_t.header_table[h]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adjustable-lawrence",
   "metadata": {},
   "source": [
    "### Task 2.3.2 (2 Points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> Run FP-Growth on the data-set (using the **retail** variable and not the small one). Try a few different values of min_support. </br>\n",
    "<span style='color: green'>**\\[Describe\\]**</span> Roughly how large does min_support need to be before all itemsets of size 1 and 2 are found but no itemsets of size 3? (You don't need to find the excact value. Nearest 1000 is fine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "authorized-watts",
   "metadata": {},
   "source": [
    "## Task 2.4 Comparing A priori and FP-Growth (3 Points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span> Run the given experiment and show to what extent FP-Growth has an advantage. Comment on the results. What do you see? What do you expect to see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - -  - -  - -  - -  n=16,a=3  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=16,a=6  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=16,a=9  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=16,a=12  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=32,a=3  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=32,a=6  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=32,a=9  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=32,a=12  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=64,a=3  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=64,a=6  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=64,a=9  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=64,a=12  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=128,a=3  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=128,a=6  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=128,a=9  - -  - -  - -  - - \n",
      "[0.00010035 0.        ] +- [0.00030105 0.        ] \n",
      "\n",
      " - -  - -  - -  - -  n=128,a=12  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=256,a=3  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=256,a=6  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=256,a=9  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=256,a=12  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=512,a=3  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=512,a=6  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=512,a=9  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=512,a=12  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=1024,a=3  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=1024,a=6  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n",
      " - -  - -  - -  - -  n=1024,a=9  - -  - -  - -  - - \n",
      "[9.98973846e-05 0.00000000e+00] +- [0.00029969 0.        ] \n",
      "\n",
      " - -  - -  - -  - -  n=1024,a=12  - -  - -  - -  - - \n",
      "[0. 0.] +- [0. 0.] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Script for testing the runtime of your algorithms. \n",
    "# WARNING: This will take a reasonably long time to run.\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "    \n",
    "def sample(n=200, alphabet_size=5):\n",
    "    candidates  = np.array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'])[:alphabet_size]\n",
    "    m = candidates.shape[0]\n",
    "    \n",
    "    T = []\n",
    "    for i in range(n):\n",
    "        size = int(np.random.rand() * (m)) + 1\n",
    "        T.append(list(candidates[np.random.permutation(m)[:size]]))\n",
    "        \n",
    "    return T\n",
    "\n",
    "def test():\n",
    "    # If you want to test it quickly, you can modify \"transaction_lengths\" and \"alphabet_sizes\" temporarily. \n",
    "    # This will give you errors in the plotting (next code cell) though.\n",
    "    # Make sure you use the original values for \"transaction_lengths\" and \"alphabet_sizes\" for your final version.\n",
    "    transaction_lengths = [2**i for i in range(4, 11)]\n",
    "    alphabet_sizes      = [3, 6, 9, 12] \n",
    "    \n",
    "    min_support = 10\n",
    "    repeats     = 10\n",
    "    \n",
    "    stop = False\n",
    "    results = np.zeros((len(transaction_lengths), len(alphabet_sizes), 2))\n",
    "    stderrs = np.zeros((len(transaction_lengths), len(alphabet_sizes), 2))\n",
    "    \n",
    "#     print(results.shape)\n",
    "    \n",
    "    for i, n in enumerate(transaction_lengths):\n",
    "        for j, a in enumerate(alphabet_sizes):\n",
    "            print(\" - - \" * 4, \"n=%d,a=%d\" % (n, a), \" - - \" * 4)\n",
    "            times = []\n",
    "            for _ in range(repeats):\n",
    "                T = sample(n, a)\n",
    "\n",
    "                t0 = time.time()\n",
    "                tree = FP_Tree(T, min_support=min_support)\n",
    "                frequent_itemsets = tree.mine_frequent_itemsets()\n",
    "                t1 = time.time() - t0\n",
    "\n",
    "                i1 = {tuple(sorted(list(k))): v for k, v in frequent_itemsets}\n",
    "\n",
    "                t0 = time.time()\n",
    "                itemsets = apriori_algorithm(T, min_support=min_support)\n",
    "                t2 = time.time() - t0\n",
    "\n",
    "                i2 = {}\n",
    "                for V in itemsets.values():\n",
    "                    for k, v in V.items():\n",
    "                        i2[tuple(sorted(list(k)))] = v\n",
    "\n",
    "                assert len(i1) == len(i2)\n",
    "                for k in i1.keys():\n",
    "                    assert i1[k] == i2[k]\n",
    "\n",
    "                times.append([t1, t2])\n",
    "\n",
    "            results[i, j] = np.mean(times, axis=0)\n",
    "            stderrs[i, j] = np.std(times, axis=0)\n",
    "            print(np.mean(times, axis=0), \"+-\", np.std(times, axis=0), \"\\n\")\n",
    "            \n",
    "    np.save('itemsets_runningtimes', results)  # Results are saved to avoid having to run it again if plot code needs changing\n",
    "    np.save('itemsets_stderr', stderrs)\n",
    "    \n",
    "    return results, stderrs\n",
    "        \n",
    "results, stderrs = test()     \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "results = np.load('itemsets_runningtimes.npy')\n",
    "stderrs = np.load('itemsets_stderr.npy')\n",
    "\n",
    "# Plotting \n",
    "transaction_lengths = [2**i for i in range(4, 11)]\n",
    "alphabet_sizes      = [3, 6, 9, 12] \n",
    "\n",
    "n, a, _ = results.shape\n",
    "res_to_plot = np.transpose(results, (1, 0, 2))\n",
    "err_to_plot = np.transpose(stderrs, (1, 0, 2))\n",
    "\n",
    "fig, ax = plt.subplots(1, a, figsize=(4*a, 4))\n",
    "for i, (res, err) in enumerate(zip(res_to_plot, err_to_plot)):\n",
    "    ax[i].plot(transaction_lengths, res[:,0], label='FP-Tree', color='C1')\n",
    "    ax[i].fill_between(transaction_lengths, res[:,0] - err[:,0], res[:,0] + err[:,0], alpha=0.3, linewidth=0 , color='C1')\n",
    "    \n",
    "    x = transaction_lengths[-1]\n",
    "    ax[i].set_xlim((2**4, 2**11))\n",
    "    ax[i].annotate(text='', xy=(x, res[-1,0]), xytext=(x,res[-1,1]), arrowprops=dict(arrowstyle='|-|'))\n",
    "    ax[i].annotate(text='%.1f $\\\\times$'%(res[-1,1]/res[-1,0]), xy=(x-24,  (res[-1,1] / 2 + res[-1,0]/2)), horizontalalignment='right')\n",
    "    \n",
    "    ax[i].plot(transaction_lengths, res[:,1], label='Apriori', color='C2')\n",
    "    ax[i].fill_between(transaction_lengths, res[:,1] - err[:,1], res[:,1] + err[:,1], alpha=0.3, linewidth=0 , color='C2')\n",
    "    \n",
    "    ax[i].set_title(\"Alphabet size: %d\" % alphabet_sizes[i])\n",
    "    ax[i].set_xscale('log', base=2)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('Number of transactions')\n",
    "    ax[i].set_ylabel('Seconds')\n",
    "\n",
    "plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-vehicle",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aerial-steps",
   "metadata": {},
   "source": [
    "# Part 3: Sequence Segmentation and LSH (30 Points)\n",
    "The Dynamic Programming algorithm for optimally segmenting a sequence $S$ of length $n$ \n",
    "into $B$ segments, that we have introduced, is expressed by the following recursive equation:\n",
    "\n",
    "$$\n",
    "E(i, b) = \\min_{j < i}\\left[ E(j, b-1) + Err(j+1, i)\\right]\n",
    "$$\n",
    "\n",
    "where $Err(j+1, i)$ is the error of a segment that contains items from $j+1$ to $i$.\n",
    "\n",
    "In this part, you will have to answer some questions on this.\n",
    "\n",
    "**Note:** \n",
    "For those of you, who are not used to analyzing algorithms: by time-complexity and space-complexity, \n",
    "we refer to the theoretical computation time and memory usage, respectively, as a function of the problem size, i.e., as a \n",
    "function of $n$ and $B$ in Problem 3. We use [Big O notation](https://en.wikipedia.org/wiki/Big_O_notation)\n",
    "to specify this. You should **not** infer it by implementing it in practice ;-) \n",
    "Again, when in doubt, ask on Discord, Blackboard or shoot Jon an email. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "specified-treasure",
   "metadata": {},
   "source": [
    "## Task 3.1 Sequence segmentation (20 Points)\n",
    "\n",
    "************\n",
    "<span style='color: red'>**These questions are hard. First complete the rest of the exercises and then come back to solve 3.1.**</span>\n",
    "************\n",
    "\n",
    "\n",
    "### Task 3.1.1\n",
    "<span style='color: green'>**\\[Describe\\]**</span> what is the default space-complexity of this algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-plaza",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-schedule",
   "metadata": {},
   "source": [
    "### Task 3.1.2 \n",
    "<span style='color: green'>**\\[Describe\\]**</span> what happens if we are willing to recompute some tabulated results. Can we then reduce the default space-complexity? _Exactly how_? What is the space-complexity then?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-threat",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-cutting",
   "metadata": {},
   "source": [
    "### Task 3.1.3 \n",
    "<span style='color: green'>**\\[Motivate\\]**</span> what is the cost of using the space-efficiency technique described in Task 3.1.2 in terms of time-complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-block",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-purchase",
   "metadata": {},
   "source": [
    "### Task 3.1.4 \n",
    "For the sub-problem of segmenting the $i$-prefix of sequence $S$ into $b$ segments, consider \n",
    "    the segment $M(i, b)$ that contains (if such segment exists) the middle item of \n",
    "    index $\\lfloor \\frac{n}{2} \\rfloor$. The boundaries of $M(i, b)$ can be detected and tabulated \n",
    "    along with each $E(i, b)$ solution. \n",
    "\n",
    "<span style='color: green'>**\\[Describe\\]**</span> a method that reduces the time-complexity burden identified in Task 3.1.3, based on the above observarion. \n",
    "    _(hint: use [divide-and-conquer](https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm))_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-antenna",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-palmer",
   "metadata": {},
   "source": [
    "### Task 3.1.5 \n",
    "<span style='color: green'>**\\[Motivate\\]**</span> what is the time complexity when using the technique proposed in Task 3.1.4?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-opinion",
   "metadata": {},
   "source": [
    "*******************\n",
    "<span style=\"color:red\">**YOUR ANSWER HERE**</span>\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-translator",
   "metadata": {},
   "source": [
    "## Task 3.2 Min Hashing (6 Points)\n",
    "\n",
    "In this exercise we will see the **One-pass implementation** of the MinHash signatures.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-latino",
   "metadata": {},
   "source": [
    "### Task 3.2.1 \n",
    "<span style='color: green'>**\\[Implement\\]**</span> Implement the One-pass algorithm for the MinHash Signatures (and the jaccard simmilarity matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C is the Input Matrix (Shingles x Documents)\n",
    "#J_sim is a jaccard similarity matrix (Documents x Documents)\n",
    "def jaccard_simmilarity_matrix(C):\n",
    "    J_sim = None\n",
    "    ### YOUR CODE STARTS HERE\n",
    "    J_sim = np.zeros((C.shape[1], C.shape[1]))\n",
    "    for i in range(C.shape[1]):\n",
    "        for j in range(i+1, C.shape[1]):\n",
    "            J_sim[i, j] = np.sum(C[:, i] == C[:, j]) / np.sum(C[:, i] != C[:, j])\n",
    "            J_sim[j, i] = J_sim[i, j]\n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return J_sim\n",
    "\n",
    "#C is the Input Matrix (Shingles x Documents)\n",
    "#no_of_permutations is the how many permutations we will use\n",
    "#C_new is the Output Matrix (no_of_permutations x Documents)\n",
    "def one_pass_hashing(C, no_of_permutations):\n",
    "    C_new = None\n",
    "    ### YOUR CODE STARTS HERE\n",
    "    # Make one pass hashing\n",
    "    C_new = np.zeros((no_of_permutations, C.shape[1]))\n",
    "    for i in range(no_of_permutations):\n",
    "        permutation = np.random.permutation(C.shape[0])\n",
    "        for j in range(C.shape[1]):\n",
    "            C_new[i, j] = np.min(permutation[C[:, j] == 1])    \n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return C_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-individual",
   "metadata": {},
   "source": [
    "### Task 3.2.2 \n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> For the matrix below run your implementation for different number of permutations in the range [1,4] and report: a) the Output Matrix C_new and  b) the jaccard similarity matrix of C_new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "recovered-return",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_new: \n",
      " [[2. 1. 0. 1.]]\n",
      "\n",
      "J_sim: \n",
      " [[0.         0.66666667 0.66666667 4.        ]\n",
      " [0.66666667 0.         0.25       1.5       ]\n",
      " [0.66666667 0.25       0.         0.25      ]\n",
      " [4.         1.5        0.25       0.        ]]\n",
      "\n",
      "C_new: \n",
      " [[2. 0. 1. 0.]\n",
      " [2. 4. 0. 2.]]\n",
      "\n",
      "J_sim: \n",
      " [[0.         0.66666667 0.66666667 4.        ]\n",
      " [0.66666667 0.         0.25       1.5       ]\n",
      " [0.66666667 0.25       0.         0.25      ]\n",
      " [4.         1.5        0.25       0.        ]]\n",
      "\n",
      "C_new: \n",
      " [[0. 2. 1. 0.]\n",
      " [3. 0. 1. 0.]\n",
      " [1. 2. 0. 1.]]\n",
      "\n",
      "J_sim: \n",
      " [[0.         0.66666667 0.66666667 4.        ]\n",
      " [0.66666667 0.         0.25       1.5       ]\n",
      " [0.66666667 0.25       0.         0.25      ]\n",
      " [4.         1.5        0.25       0.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "A = np.array([[1, 0, 0, 1, 0], [0, 0, 1, 0, 0], [0, 1, 0, 1, 1], [1, 0, 1, 1, 0]]).transpose()\n",
    "\n",
    "for i in range(1, 4):\n",
    "    print('C_new: \\n', one_pass_hashing(A, i))\n",
    "    print()\n",
    "    print('J_sim: \\n', jaccard_simmilarity_matrix(A))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-siemens",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span> Suppose we have 4 documents named as X,Y,Z and W and their signatures are given by the input matrix $C$ as:\n",
    "$$\\begin{matrix} X & Y & Z & W \\\\1 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 1\\\\0 & 0 & 1 & 0 \\end{matrix}$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "proper-letter",
   "metadata": {},
   "source": [
    "*******************\n",
    "Petros Petsinis wrote that this was a typo so we will not give any answer.\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "close-confusion",
   "metadata": {},
   "source": [
    "### Task 3.2.3 \n",
    "Suppose we have two hash functions (permutations) as <br> $h_1(x) = (x + 1) mod 5$  and  $h_2(x)=(3x + 1) mod 5$ \n",
    "<span style='color: green'>**\\[Describe\\]**</span> and <span style='color: green'>**\\[Compute by Hand\\]**</span> the steps of the one-pass implementation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "obvious-cemetery",
   "metadata": {},
   "source": [
    "*******************\n",
    "First we initialize two tables T1 and T2 which are going to be the corresponding hashtables for h1 and h2 respectively:\n",
    "\n",
    "T1 = []\n",
    "T2 = []\n",
    "\n",
    "Then for each row in matrix C, we are going to evaluate the two hash functions on the index and receive the corresponding index in which we store the value from the original matrix C.\n",
    "After we are going to interchange the order responsing to the hash evaluated on the index of each row, obtaining T1 and T2 respectively:\n",
    "\n",
    "$h1(0) = (0 + 1) \\mod 5 = 1$ <br>\n",
    "$h1(1) = (1 + 1) \\mod 5 = 2$ <br>\n",
    "$h1(2) = (2 + 1) \\mod 5 = 3$ <br>\n",
    "$h1(3) = (3 + 1) \\mod 5 = 4$ <br>\n",
    "$h1(4) = (4 + 1) \\mod 5 = 0$ <br>\n",
    "\n",
    "This gives us the table T1:\n",
    "\n",
    "$T1 = \\begin{matrix} X & Y & Z & W \\\\0 & 0 & 1 & 0\\\\1 & 0 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 1 & 0 & 1 & 1 \\end{matrix}$\n",
    "\n",
    "$h2(0) = (0 * 3 + 1) \\mod 5 = 1$ <br>\n",
    "$h2(1) = (1 * 3 + 1) \\mod 5 = 4$ <br>\n",
    "$h2(2) = (2 * 3 + 1) \\mod 5 = 2$ <br>\n",
    "$h2(3) = (3 * 3 + 1) \\mod 5 = 0$ <br>\n",
    "$h2(4) = (4 * 3 + 1) \\mod 5 = 3$ <br>\n",
    "\n",
    "\n",
    "\n",
    "$\\begin{matrix}T2 =  X & Y & Z & W \\\\0 & 0 & 1 & 0 \\\\0 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1 \\\\1 & 0 & 0 & 1 \\\\ 1 & 0 & 1 & 1 \\end{matrix}$\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-alliance",
   "metadata": {},
   "source": [
    "## Task 3.3 Locality Sensitive Hashing (4 points)\n",
    "\n",
    "### Task 3.3.1 \n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> code that evaluate the S-curve $1-(1-s^r)^b$ for $s\\in [0,1]$ for the following values of $r$ and $b$ \n",
    "1. $r = 3$ and $b = 10$\n",
    "2. $r = 6$ and $b = 20$\n",
    "3. $r = 5$ and $b = 50$\n",
    "\n",
    "You can use, or modify, the helper plotting code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "liquid-singapore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### YOUR CODE HERE\n",
    "def s_curve(r, b):\n",
    "    def f(x):\n",
    "        return 1 - (1 - x**r)**b\n",
    "    return f\n",
    "### YOUR CODE HERE\n",
    "\n",
    "x = np.linspace(0.01,0.99,100)\n",
    "y = s_curve(5,50)(x)\n",
    "\n",
    "def plot_function(x,y): \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    # plot the function\n",
    "    plt.plot(x,y, 'r')\n",
    "\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "plot_function(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entire-rebel",
   "metadata": {},
   "source": [
    "### Task 3.3.2 \n",
    "\n",
    "<span style='color: green'>**\\[Describe\\]**</span> For each of the (r,b) pairs in Task 3.2.1, compute the value of $s$ for which the value of $1-(1-s^r)^b$ is exactly 1/2. How does this value compare with the estimate of $(1/b)^{1/r}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r = 3, b = 10\n",
      "s_curve_inverse(0.5) = 0.406\n",
      "s_curve(0.5) = 0.500\n",
      "estimate(3.0, 10.0) = 0.464\n",
      "diff(0.500, 0.464) = -0.036\n",
      "\n",
      "r = 6, b = 20\n",
      "s_curve_inverse(0.5) = 0.569\n",
      "s_curve(0.5) = 0.500\n",
      "estimate(6.0, 20.0) = 0.607\n",
      "diff(0.500, 0.607) = 0.107\n",
      "\n",
      "r = 5, b = 50\n",
      "s_curve_inverse(0.5) = 0.424\n",
      "s_curve(0.5) = 0.500\n",
      "estimate(5.0, 50.0) = 0.457\n",
      "diff(0.500, 0.457) = -0.043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = [[3, 10], [6, 20], [5, 50]]\n",
    "\n",
    "def estimate(r,b):\n",
    "    return (1 / b)**(1/r)\n",
    "\n",
    "def s_curve_inverse(r, b):\n",
    "    x = (1 - (1/2) ** (1/b))**(1/r)\n",
    "    return x\n",
    "\n",
    "\n",
    "for r, b in params:\n",
    "    print('r = %d, b = %d' % (r, b))\n",
    "    print('s_curve_inverse(0.5) = %.3f' % s_curve_inverse(r, b))\n",
    "    print('s_curve(0.5) = %.3f' % s_curve(r, b)(s_curve_inverse(r, b)))\n",
    "    print('estimate(%.1f, %.1f) = %.3f' % (r, b, estimate(r, b)))\n",
    "    print('diff(%.3f, %.3f) = %.3f' % (s_curve(r, b)(s_curve_inverse(r, b)), estimate(r, b), estimate(r, b) - s_curve(r, b)(s_curve_inverse(r,b))))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "controlled-austin",
   "metadata": {},
   "source": [
    "*******************\n",
    "We found that getting the value for when $s\\_curve(r,b)(x) = 1/2$ is the expression $$x = \\sqrt[r]{1 - \\sqrt[b]{\\frac{1}{2}}}$$\n",
    "The difference for the given r and b values are between -0.036 and 0.107. The small positive or negative difference indicates a reasonably accurate estimate. Howewer if we were to test further and find, that the differene become to large, the estimate would be less accurate than first assumed.\n",
    "\n",
    "******************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
